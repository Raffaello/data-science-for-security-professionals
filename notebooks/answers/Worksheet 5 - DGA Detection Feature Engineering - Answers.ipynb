{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, tree, model_selection, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet - Answer - DGA Detection using Machine Learning\n",
    "\n",
    "This worksheet is a step-by-step guide on how to detect domains that were generated using \"Domain Generation Algorithm\" (DGA). We will walk you through the process of transforming raw domain strings to Machine Learning features and creating a decision tree classifer which you will use to determine whether a given domain is legit or not. Once you have implemented the classifier, the worksheet will walk you through evaluating your model.  \n",
    "\n",
    "Overview 2 main steps:\n",
    "\n",
    "1. **Feature Engineering** - from raw domain strings to numeric Machine Learning features using DataFrame manipulations\n",
    "2. **Machine Learning Classification** - predict whether a domain is legit or not using a Decision Tree Classifier\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "**DGA - Background**\n",
    "\n",
    "\"Various families of malware use domain generation\n",
    "algorithms (DGAs) to generate a large number of pseudo-random\n",
    "domain names to connect to a command and control (C2) server.\n",
    "In order to block DGA C2 traffic, security organizations must\n",
    "first discover the algorithm by reverse engineering malware\n",
    "samples, then generate a list of domains for a given seed. The\n",
    "domains are then either preregistered, sink-holed or published\n",
    "in a DNS blacklist. This process is not only tedious, but can\n",
    "be readily circumvented by malware authors. An alternative\n",
    "approach to stop malware from using DGAs is to intercept DNS\n",
    "queries on a network and predict whether domains are DGA\n",
    "generated. Much of the previous work in DGA detection is based\n",
    "on finding groupings of like domains and using their statistical\n",
    "properties to determine if they are DGA generated. However,\n",
    "these techniques are run over large time windows and cannot be\n",
    "used for real-time detection and prevention. In addition, many of\n",
    "these techniques also use contextual information such as passive\n",
    "DNS and aggregations of all NXDomains throughout a network.\n",
    "Such requirements are not only costly to integrate, they may not\n",
    "be possible due to real-world constraints of many systems (such\n",
    "as endpoint detection). An alternative to these systems is a much\n",
    "harder problem: detect DGA generation on a per domain basis\n",
    "with no information except for the domain name. Previous work\n",
    "to solve this harder problem exhibits poor performance and many\n",
    "of these systems rely heavily on manual creation of features;\n",
    "a time consuming process that can easily be circumvented by\n",
    "malware authors...\"    \n",
    "[Citation: Woodbridge et. al 2016: \"Predicting Domain Generation Algorithms with Long Short-Term Memory Networks\"]\n",
    "\n",
    "A better alternative for real-world deployment would be to use \"featureless deep learning\" - We have a separate notebook where you can see how this can be implemented!\n",
    "\n",
    "**However, let's learn the basics first!!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet for Part 1 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isDGA</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>legit</td>\n",
       "      <td>lushusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>dga</td>\n",
       "      <td>zmjbv6xj9cch3hvqcw1meov5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>legit</td>\n",
       "      <td>tu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>legit</td>\n",
       "      <td>postlets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>legit</td>\n",
       "      <td>cymax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      isDGA                     domain\n",
       "1638  legit                    lushusa\n",
       "208     dga  zmjbv6xj9cch3hvqcw1meov5k\n",
       "1695  legit                         tu\n",
       "1562  legit                   postlets\n",
       "1206  legit                      cymax"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load data\n",
    "df = pd.read_csv('../../data/dga_data_small.csv')\n",
    "df.drop(['host', 'subclass'], axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.sample(n=5).head() # print a random sample of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isDGA</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>legit</td>\n",
       "      <td>empressr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>legit</td>\n",
       "      <td>noticiasvenezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>legit</td>\n",
       "      <td>iptorrents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>legit</td>\n",
       "      <td>parspal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>legit</td>\n",
       "      <td>onlineschooladmissions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      isDGA                  domain\n",
       "1000  legit                empressr\n",
       "1001  legit       noticiasvenezuela\n",
       "1002  legit              iptorrents\n",
       "1003  legit                 parspal\n",
       "1004  legit  onlineschooladmissions"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isDGA == 'legit'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8857</th>\n",
       "      <td>gig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>slight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>suggests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8411</th>\n",
       "      <td>hack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>install</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words\n",
       "8857       gig\n",
       "7515    slight\n",
       "4616  suggests\n",
       "8411      hack\n",
       "2002   install"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google's 10000 most common english words will be needed to derive a feature called ngrams...\n",
    "# therefore we already load them here.\n",
    "top_en_words = pd.read_csv('../../data/google-10000-english.txt', header=None, names=['words'])\n",
    "top_en_words.sample(n=5).head()\n",
    "# Source: https://github.com/first20hours/google-10000-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Feature Engineering\n",
    "\n",
    "Option 1 to derive Machine Learning features is to manually hand-craft useful contextual information of the domain string. An alternative approach (not covered in this notebook) is \"Featureless Deep Learning\", where an embedding layer takes care of deriving features - a huge step towards more \"AI\".\n",
    "\n",
    "Previous academic research has focused on the following features that are based on contextual information:\n",
    "\n",
    "**List of features**:\n",
    "\n",
    "1. Length [\"length\"]\n",
    "2. Number of digits [\"digits\"]\n",
    "3. Entropy [\"entropy\"] - use ```H_entropy``` function provided \n",
    "4. Vowel to consonant ratio [\"vowel-cons\"] - use ```vowel_consonant_ratio``` function provided\n",
    "5. N-grams [\"n-grams\"] - use ```ngram``` functions provided\n",
    "\n",
    "**Tasks**:    \n",
    "Split into A and B parts, see below...\n",
    "\n",
    "\n",
    "Please run the following function cell and then continue reading the next markdown cell with more details on how to derive those features. Have fun!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_entropy (x):\n",
    "    # Calculate Shannon Entropy\n",
    "    prob = [ float(x.count(c)) / len(x) for c in dict.fromkeys(list(x)) ] \n",
    "    H = - sum([ p * np.log2(p) for p in prob ]) \n",
    "    return H\n",
    "\n",
    "def vowel_consonant_ratio (x):\n",
    "    # Calculate vowel to consonant ratio\n",
    "    x = x.lower()\n",
    "    vowels_pattern = re.compile('([aeiou])')\n",
    "    consonants_pattern = re.compile('([b-df-hj-np-tv-z])')\n",
    "    vowels = re.findall(vowels_pattern, x)\n",
    "    consonants = re.findall(consonants_pattern, x)\n",
    "    try:\n",
    "        ratio = len(vowels) / len(consonants)\n",
    "    except: # catch zero devision exception \n",
    "        ratio = 0  \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks - A - Feature Engineering\n",
    "\n",
    "Please try to derive a new pandas 2D DataFrame with a new column for each of feature. Focus on ```length```, ```digits```, ```entropy``` and ```vowel-cons``` here. Also make sure to encode the ```isDGA``` column as integers. [pandas.Series.str](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.html), [pandas.Series.replace](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.replace.html) and [pandas.Series,apply](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.apply.html) can be very helpful to quickly derive those features. Functions you need to apply here are provided in above cell.\n",
    "\n",
    "The ```ngram``` is a bit more complicated, see next instruction cell to add this feature...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1000\n",
      "0    1000\n",
      "Name: isDGA, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isDGA</th>\n",
       "      <th>domain</th>\n",
       "      <th>length</th>\n",
       "      <th>digits</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vowel-cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>1ozsk5qll8k9zffte2u16u7vpu</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>4.132944</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>0</td>\n",
       "      <td>keb</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>0</td>\n",
       "      <td>freeforums</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.721928</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>swkndhanaxcnak</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2.985228</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>19d0ggogoltk117iipybxu248l</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>4.103910</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      isDGA                      domain  length  digits   entropy  vowel-cons\n",
       "829       1  1ozsk5qll8k9zffte2u16u7vpu      26       8  4.132944    0.384615\n",
       "1711      0                         keb       3       0  1.584963    0.500000\n",
       "1667      0                  freeforums      10       0  2.721928    0.666667\n",
       "212       1              swkndhanaxcnak      14       0  2.985228    0.272727\n",
       "205       1  19d0ggogoltk117iipybxu248l      26       9  4.103910    0.416667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# derive features\n",
    "df['length'] = df.domain.str.len()\n",
    "df['digits'] = df.domain.str.count('[0-9]')\n",
    "df['entropy'] = df.domain.apply(H_entropy)\n",
    "df['vowel-cons'] = df.domain.apply(vowel_consonant_ratio)\n",
    "\n",
    "# encode strings of target variable as integers\n",
    "df.isDGA = df.isDGA.replace(to_replace = 'dga', value=1)\n",
    "df.isDGA = df.isDGA.replace(to_replace = 'legit', value=0)\n",
    "print(df.isDGA.value_counts())\n",
    "\n",
    "# check intermediate 2D pandas DataFrame\n",
    "df.sample(n=5).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks - B - Feature Engineering\n",
    "\n",
    "Finally, let's tackle the **ngram** feature. There are multiple steps involved to derive this feature. Here in this notebook, we use an implementation outlined in the this academic paper [Schiavoni 2014: \"Phoenix: DGA-based Botnet Tracking and Intelligence\" - see section: Linguistic Features](http://s2lab.isg.rhul.ac.uk/papers/files/dimva2014.pdf).\n",
    "\n",
    "\n",
    "- **What are ngrams???** Imagine a string like 'facebook', if I were to derive all n-grams for n=2 (aka bi-grams) I would get '['fa', 'ac', 'ce', 'eb', 'bo', 'oo', 'ok']', so you see that you slide with one step from the left and just group 2 characters together each time, a tri-gram for 'facebook' would yielfd '['fac', 'ace', 'ceb', 'ebo', 'boo', 'ook']'. Ngrams have a long history in natural language processing, but are also used a lot for example in detecting malicious executable (raw byte ngrams in this case).\n",
    "\n",
    "Steps involved:\n",
    "\n",
    "1. We have the 10000 most common english words (see data file we loaded, we call this DataFrame ```top_en_words``` in this notebook). Now we run the ```ngrams``` functions on a list of all these words. The output here is a list that contains ALL 1-grams, bi-grams and tri-grams of these 10000 most common english words.\n",
    "2. We use the ```Counter``` function from collections to derive a dictionary ```d``` that contains the counts of all unique 1-grams, bi-grams and tri-grams.\n",
    "3. Our ```ngram_feature``` function will do the core magic. It takes your domain as input, splits it into ngrams (n is a function parameter) and then looks up these ngrams in the english dictionary ```d``` we derived in step 2. Function returns the normalized sum of all ngrams that were contained in the english dictionary. For example, running ```ngram_feature('facebook', d, 2)``` will return 171.28 (this value is just like the one published in the Schiavoni paper).\n",
    "4. Finally ```average_ngram_feature``` wraps around ```ngram_feature```. You will use this function as your task is to derive a feature that gives the average of the ngram_feature for n=1,2 and 3. Input to this function should be a simple list with entries calling ```ngram_feature``` with n=1,2 and 3, hence a list of 3 ngram_feature results.   \n",
    "5. **YOUR TURN: Apply ```average_ngram_feature``` to you domain column in the DataFrame thereby adding ```ngram``` to the df.**\n",
    "6. **YOUR TURN: Finally drop the ```domain``` column from your DataFrame**.\n",
    "\n",
    "\n",
    "Please run the following function cell and then write your code in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams: Implementation according to Schiavoni 2014: \"Phoenix: DGA-based Botnet Tracking and Intelligence\"\n",
    "# http://s2lab.isg.rhul.ac.uk/papers/files/dimva2014.pdf\n",
    "\n",
    "def ngrams(word, n):\n",
    "    # Extract all ngrams and return a regular Python list\n",
    "    # Input word: can be a simple string or a list of strings\n",
    "    # Input n: Can be one integer or a list of integers \n",
    "    # if you want to extract multipe ngrams and have them all in one list\n",
    "    \n",
    "    l_ngrams = []\n",
    "    if isinstance(word, list):\n",
    "        for w in word:\n",
    "            if isinstance(n, list):\n",
    "                for curr_n in n:\n",
    "                    ngrams = [w[i:i+curr_n] for i in range(0,len(w)-curr_n+1)]\n",
    "                    l_ngrams.extend(ngrams)\n",
    "            else:\n",
    "                ngrams = [w[i:i+n] for i in range(0,len(w)-n+1)]\n",
    "                l_ngrams.extend(ngrams)\n",
    "    else:\n",
    "        if isinstance(n, list):\n",
    "            for curr_n in n:\n",
    "                ngrams = [word[i:i+curr_n] for i in range(0,len(word)-curr_n+1)]\n",
    "                l_ngrams.extend(ngrams)\n",
    "        else:\n",
    "            ngrams = [word[i:i+n] for i in range(0,len(word)-n+1)]\n",
    "            l_ngrams.extend(ngrams)\n",
    "#     print(l_ngrams)\n",
    "    return l_ngrams\n",
    "\n",
    "def ngram_feature(domain, d, n):\n",
    "    # Input is your domain string or list of domain strings\n",
    "    # a dictionary object d that contains the count for most common english words\n",
    "    # finally you n either as int list or simple int defining the ngram length\n",
    "    \n",
    "    # Core magic: Looks up domain ngrams in english dictionary ngrams and sums up the \n",
    "    # respective english dictionary counts for the respective domain ngram\n",
    "    # sum is normalized\n",
    "    \n",
    "    l_ngrams = ngrams(domain, n)\n",
    "#     print(l_ngrams)\n",
    "    count_sum=0\n",
    "    for ngram in l_ngrams:\n",
    "        if d[ngram]:\n",
    "            count_sum+=d[ngram]\n",
    "    try:\n",
    "        feature = count_sum/(len(domain)-n+1)\n",
    "    except:\n",
    "        feature = 0\n",
    "    return feature\n",
    "    \n",
    "def average_ngram_feature(l_ngram_feature):\n",
    "    # input is a list of calls to ngram_feature(domain, d, n)\n",
    "    # usually you would use various n values, like 1,2,3...\n",
    "    return sum(l_ngram_feature)/len(l_ngram_feature)\n",
    "\n",
    "\n",
    "l_en_ngrams = ngrams(list(top_en_words['words']), [1,2,3])\n",
    "d = Counter(l_en_ngrams)\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "with open('../../data/d_common_en_words' + '.pickle', 'wb') as f:\n",
    "        pickle.dump(d, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isDGA</th>\n",
       "      <th>domain</th>\n",
       "      <th>length</th>\n",
       "      <th>digits</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vowel-cons</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>1</td>\n",
       "      <td>dreamopen</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.947703</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1658.669312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>0</td>\n",
       "      <td>telexplorer</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2.663533</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1705.498990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>0</td>\n",
       "      <td>mitsubishi-motors</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3.175123</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1322.554330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>1</td>\n",
       "      <td>dfjpnpvmfgbb</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.084963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>561.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>0</td>\n",
       "      <td>linkwheeltool</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3.026987</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1414.654040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      isDGA             domain  length  digits   entropy  vowel-cons  \\\n",
       "712       1          dreamopen       9       0  2.947703    0.800000   \n",
       "1272      0        telexplorer      11       0  2.663533    0.571429   \n",
       "1123      0  mitsubishi-motors      17       0  3.175123    0.600000   \n",
       "816       1       dfjpnpvmfgbb      12       0  3.084963    0.000000   \n",
       "1331      0      linkwheeltool      13       0  3.026987    0.625000   \n",
       "\n",
       "           ngrams  \n",
       "712   1658.669312  \n",
       "1272  1705.498990  \n",
       "1123  1322.554330  \n",
       "816    561.444444  \n",
       "1331  1414.654040  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ngrams'] = df.domain.apply(lambda x: average_ngram_feature([ngram_feature(x, d, 1), \n",
    "                                                                ngram_feature(x, d, 2), \n",
    "                                                                ngram_feature(x, d, 3)]))\n",
    "\n",
    "# check final 2D pandas DataFrame containing all final features and the target vector isDGA\n",
    "df.sample(n=5).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isDGA</th>\n",
       "      <th>length</th>\n",
       "      <th>digits</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vowel-cons</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3.546594</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>968.076729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3.833270</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>481.067222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.855389</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1036.365657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3.844107</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>708.328718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.084963</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>897.543434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isDGA  length  digits   entropy  vowel-cons       ngrams\n",
       "0      1      13       0  3.546594    0.300000   968.076729\n",
       "1      1      25      10  3.833270    0.250000   481.067222\n",
       "2      1      12       0  2.855389    0.090909  1036.365657\n",
       "3      1      26       6  3.844107    0.052632   708.328718\n",
       "4      1      12       0  3.084963    0.090909   897.543434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df\n",
    "df_final = df_final.drop(['domain'], axis=1)\n",
    "df_final.to_csv('../../data/dga_features_final_df.csv', index=False)\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breakpoint: Load Features and Labels\n",
    "\n",
    "If you got stuck in Part 1, please simply load the feature matrix we prepared for you, so you can move on to Part 2 and train a Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1000\n",
      "0    1000\n",
      "Name: isDGA, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isDGA</th>\n",
       "      <th>length</th>\n",
       "      <th>digits</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vowel-cons</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3.546594</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>968.076729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3.833270</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>481.067222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.855389</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1036.365657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3.844107</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>708.328718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.084963</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>897.543434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isDGA  length  digits   entropy  vowel-cons       ngrams\n",
       "0      1      13       0  3.546594    0.300000   968.076729\n",
       "1      1      25      10  3.833270    0.250000   481.067222\n",
       "2      1      12       0  2.855389    0.090909  1036.365657\n",
       "3      1      26       6  3.844107    0.052632   708.328718\n",
       "4      1      12       0  3.084963    0.090909   897.543434"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.read_csv('../../data/dga_features_final_df.csv')\n",
    "print(df_final.isDGA.value_counts())\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
